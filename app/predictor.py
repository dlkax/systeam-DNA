"""
Sistema de PrediÃ§Ã£o de FÃ³sseis com Alta ConfianÃ§a
VersÃ£o 3.0 - Com melhorias para aumentar a precisÃ£o
"""

import json
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
import os
from pathlib import Path
import cv2
from typing import Dict, Tuple, List

# Caminhos
MODEL_PATH = "saved_model/fossil_classifier.h5"
LABELS_PATH = "model/labels.json"

# ConfiguraÃ§Ãµes de prediÃ§Ã£o
IMG_SIZE = (128, 128)
CONFIDENCE_THRESHOLD = 70.0  # Limiar mÃ­nimo de confianÃ§a
TOP_K_PREDICTIONS = 3  # Mostrar top 3 prediÃ§Ãµes

class FossilPredictor:
    """Classe aprimorada para prediÃ§Ã£o de espÃ©cies fÃ³sseis"""
    
    def __init__(self):
        """Inicializa o preditor carregando modelo e labels"""
        self.model = None
        self.labels = None
        self.species_info = None
        self._load_model()
        self._load_labels()
        self._load_species_info()
        
    def _load_model(self):
        """Carrega o modelo treinado"""
        if not os.path.exists(MODEL_PATH):
            raise FileNotFoundError(f"âŒ Modelo nÃ£o encontrado: {MODEL_PATH}")
        
        print("ğŸ“‚ Carregando modelo...")
        self.model = tf.keras.models.load_model(MODEL_PATH)
        print("âœ… Modelo carregado com sucesso!")
        
    def _load_labels(self):
        """Carrega o mapeamento de labels"""
        if not os.path.exists(LABELS_PATH):
            raise FileNotFoundError(f"âŒ Labels nÃ£o encontrados: {LABELS_PATH}")
        
        with open(LABELS_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
            
        # Suporta diferentes formatos de labels.json
        if isinstance(data, dict):
            if "id_to_name" in data:
                self.labels = data["id_to_name"]
            elif "0" in data or 0 in data:
                self.labels = data
            else:
                self.labels = {str(i): name for i, name in enumerate(data.keys())}
        else:
            self.labels = {str(i): name for i, name in enumerate(data)}
            
        print(f"âœ… {len(self.labels)} classes carregadas")
        
    def _load_species_info(self):
        """Carrega informaÃ§Ãµes detalhadas das espÃ©cies"""
        self.species_info = {
            "mammuthus_primigenius": {
                "nome_comum": "Mamute-lanoso",
                "periodo": "Pleistoceno (2.5 milhÃµes - 10.000 anos atrÃ¡s)",
                "descricao": "MamÃ­fero proboscÃ­deo extinto, adaptado ao clima frio com pelagem espessa. Parente dos elefantes modernos.",
                "habitat": "Tundra e estepes do hemisfÃ©rio norte",
                "tamanho": "3-4 metros de altura, 6 toneladas"
            },
            "smilodon": {
                "nome_comum": "Tigre-dentes-de-sabre",
                "periodo": "Pleistoceno (2.5 milhÃµes - 10.000 anos atrÃ¡s)",
                "descricao": "Felino prÃ©-histÃ³rico com caninos de atÃ© 28cm, predador apex de sua Ã©poca.",
                "habitat": "AmÃ©ricas do Norte e Sul",
                "tamanho": "1-1.2m de altura, 160-280kg"
            },
            "smilodon_fatalis": {
                "nome_comum": "Tigre-dentes-de-sabre americano",
                "periodo": "Pleistoceno",
                "descricao": "SubespÃ©cie de Smilodon encontrada principalmente na AmÃ©rica do Norte. Extremamente musculoso.",
                "habitat": "Florestas e savanas da AmÃ©rica do Norte",
                "tamanho": "1m de altura, atÃ© 280kg"
            },
            "megatherium": {
                "nome_comum": "PreguiÃ§a-gigante",
                "periodo": "Plioceno ao Pleistoceno",
                "descricao": "MamÃ­fero gigante herbÃ­voro, uma das maiores preguiÃ§as terrestres que jÃ¡ existiram.",
                "habitat": "AmÃ©rica do Sul",
                "tamanho": "6m de comprimento, 4 toneladas"
            },
            "preguica_gigante": {
                "nome_comum": "PreguiÃ§a-gigante",
                "periodo": "Pleistoceno",
                "descricao": "Megafauna herbÃ­vora terrestre, ancestral das preguiÃ§as modernas mas de proporÃ§Ãµes gigantescas.",
                "habitat": "Florestas e campos da AmÃ©rica do Sul",
                "tamanho": "AtÃ© 6m de comprimento"
            }
        }
    
    def preprocess_image_advanced(self, img_path: str) -> np.ndarray:
        """
        Preprocessamento avanÃ§ado da imagem para melhor prediÃ§Ã£o
        """
        # Carregar imagem com OpenCV para preprocessamento avanÃ§ado
        img_cv = cv2.imread(img_path)
        if img_cv is None:
            raise ValueError(f"NÃ£o foi possÃ­vel carregar a imagem: {img_path}")
        
        # Converter BGR para RGB
        img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
        
        # Aplicar CLAHE (Contrast Limited Adaptive Histogram Equalization)
        # para melhorar o contraste
        lab = cv2.cvtColor(img_cv, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        l = clahe.apply(l)
        img_enhanced = cv2.merge([l, a, b])
        img_enhanced = cv2.cvtColor(img_enhanced, cv2.COLOR_LAB2RGB)
        
        # Redimensionar mantendo aspect ratio
        img_resized = self._resize_with_padding(img_enhanced, IMG_SIZE)
        
        # Normalizar
        img_normalized = img_resized.astype(np.float32) / 255.0
        
        # Expandir dimensÃµes para batch
        img_batch = np.expand_dims(img_normalized, axis=0)
        
        return img_batch
    
    def _resize_with_padding(self, img: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
        """Redimensiona mantendo aspect ratio e adiciona padding se necessÃ¡rio"""
        h, w = img.shape[:2]
        target_h, target_w = target_size
        
        # Calcular scale mantendo aspect ratio
        scale = min(target_w/w, target_h/h)
        new_w = int(w * scale)
        new_h = int(h * scale)
        
        # Redimensionar
        resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
        
        # Criar imagem com padding
        padded = np.zeros((target_h, target_w, 3), dtype=np.uint8)
        padded[:] = [128, 128, 128]  # Cor cinza para padding
        
        # Centralizar imagem redimensionada
        y_offset = (target_h - new_h) // 2
        x_offset = (target_w - new_w) // 2
        padded[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
        
        return padded
    
    def predict_with_augmentation(self, img_path: str, n_augmentations: int = 5) -> np.ndarray:
        """
        Faz prediÃ§Ã£o usando Test Time Augmentation (TTA) para maior precisÃ£o
        """
        predictions = []
        
        # PrediÃ§Ã£o original
        img_batch = self.preprocess_image_advanced(img_path)
        pred = self.model.predict(img_batch, verbose=0)
        predictions.append(pred[0])
        
        # AugmentaÃ§Ãµes para TTA
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        for i in range(n_augmentations - 1):
            # Aplicar diferentes augmentaÃ§Ãµes
            augmented = img.copy()
            
            if i == 0:  # Flip horizontal
                augmented = cv2.flip(augmented, 1)
            elif i == 1:  # RotaÃ§Ã£o pequena
                angle = np.random.uniform(-10, 10)
                center = (augmented.shape[1]//2, augmented.shape[0]//2)
                M = cv2.getRotationMatrix2D(center, angle, 1.0)
                augmented = cv2.warpAffine(augmented, M, (augmented.shape[1], augmented.shape[0]))
            elif i == 2:  # Ajuste de brilho
                value = np.random.uniform(0.8, 1.2)
                augmented = cv2.convertScaleAbs(augmented, alpha=value, beta=0)
            elif i == 3:  # Zoom leve
                scale = np.random.uniform(0.9, 1.1)
                center = (augmented.shape[1]//2, augmented.shape[0]//2)
                M = cv2.getRotationMatrix2D(center, 0, scale)
                augmented = cv2.warpAffine(augmented, M, (augmented.shape[1], augmented.shape[0]))
            
            # Preprocessar e prever
            augmented = cv2.resize(augmented, IMG_SIZE)
            augmented = augmented.astype(np.float32) / 255.0
            augmented = np.expand_dims(augmented, axis=0)
            
            pred = self.model.predict(augmented, verbose=0)
            predictions.append(pred[0])
        
        # MÃ©dia das prediÃ§Ãµes (ensemble)
        final_prediction = np.mean(predictions, axis=0)
        
        return final_prediction
    
    def apply_confidence_calibration(self, predictions: np.ndarray) -> np.ndarray:
        """
        Aplica calibraÃ§Ã£o de confianÃ§a para tornar as probabilidades mais realistas
        """
        # Temperature scaling
        temperature = 1.5  # Ajuste este valor baseado na validaÃ§Ã£o
        scaled_logits = np.log(predictions + 1e-10) / temperature
        calibrated = np.exp(scaled_logits) / np.sum(np.exp(scaled_logits))
        
        return calibrated
    
    def predict_species(self, img_path: str, use_tta: bool = True) -> Dict:
        """
        PrediÃ§Ã£o principal com todas as melhorias
        """
        try:
            # Verificar se arquivo existe
            if not os.path.exists(img_path):
                return {"erro": f"Arquivo nÃ£o encontrado: {img_path}"}
            
            print(f"\nğŸ”¬ Analisando: {os.path.basename(img_path)}")
            
            # Fazer prediÃ§Ã£o (com ou sem TTA)
            if use_tta:
                print("  ğŸ“Š Aplicando Test Time Augmentation...")
                predictions = self.predict_with_augmentation(img_path)
            else:
                img_batch = self.preprocess_image_advanced(img_path)
                predictions = self.model.predict(img_batch, verbose=0)[0]
            
            # Aplicar calibraÃ§Ã£o
            predictions = self.apply_confidence_calibration(predictions)
            
            # Obter top K prediÃ§Ãµes
            top_k_indices = np.argsort(predictions)[-TOP_K_PREDICTIONS:][::-1]
            
            # Resultado principal
            best_idx = top_k_indices[0]
            best_confidence = predictions[best_idx] * 100
            
            # Obter nome da espÃ©cie
            species_name = self._get_species_name(best_idx)
            
            # Verificar qualidade da prediÃ§Ã£o
            quality = self._assess_prediction_quality(predictions)
            
            # Montar resultado
            result = {
                "especie": species_name,
                "confianca": f"{best_confidence:.1f}%",
                "qualidade_predicao": quality,
                "arquivo": os.path.basename(img_path),
                "top_3_predicoes": []
            }
            
            # Adicionar top 3 prediÃ§Ãµes
            for idx in top_k_indices:
                species = self._get_species_name(idx)
                conf = predictions[idx] * 100
                result["top_3_predicoes"].append({
                    "especie": species,
                    "confianca": f"{conf:.1f}%"
                })
            
            # Adicionar informaÃ§Ãµes da espÃ©cie se disponÃ­vel
            if species_name in self.species_info:
                result["info_detalhada"] = self.species_info[species_name]
            
            # Adicionar recomendaÃ§Ã£o baseada na confianÃ§a
            if best_confidence < 60:
                result["recomendacao"] = "âš ï¸ ConfianÃ§a muito baixa. Considere tirar uma foto melhor ou de Ã¢ngulo diferente."
            elif best_confidence < 80:
                result["recomendacao"] = "âš¡ ConfianÃ§a moderada. Resultado pode precisar de verificaÃ§Ã£o adicional."
            else:
                result["recomendacao"] = "âœ… Alta confianÃ§a na identificaÃ§Ã£o!"
            
            return result
            
        except Exception as e:
            return {"erro": f"Erro ao processar imagem: {str(e)}"}
    
    def _get_species_name(self, idx: int) -> str:
        """ObtÃ©m o nome da espÃ©cie pelo Ã­ndice"""
        if str(idx) in self.labels:
            return self.labels[str(idx)]
        elif idx in self.labels:
            return self.labels[idx]
        else:
            return f"especie_desconhecida_{idx}"
    
    def _assess_prediction_quality(self, predictions: np.ndarray) -> str:
        """Avalia a qualidade da prediÃ§Ã£o baseada na distribuiÃ§Ã£o de probabilidades"""
        max_prob = np.max(predictions)
        entropy = -np.sum(predictions * np.log(predictions + 1e-10))
        
        if max_prob > 0.8 and entropy < 0.5:
            return "EXCELENTE"
        elif max_prob > 0.6 and entropy < 1.0:
            return "BOA"
        elif max_prob > 0.4:
            return "MODERADA"
        else:
            return "BAIXA"
    
    def analyze_batch(self, image_folder: str) -> List[Dict]:
        """Analisa mÃºltiplas imagens de uma pasta"""
        results = []
        extensions = ['.jpg', '.jpeg', '.png', '.bmp']
        
        for file in os.listdir(image_folder):
            if any(file.lower().endswith(ext) for ext in extensions):
                img_path = os.path.join(image_folder, file)
                result = self.predict_species(img_path)
                results.append(result)
        
        return results

def display_result(result: Dict):
    """Exibe o resultado de forma formatada"""
    print("\n" + "="*60)
    
    if "erro" in result:
        print(f"âŒ ERRO: {result['erro']}")
    else:
        print("ğŸ¦´ ANÃLISE DE FÃ“SSIL CONCLUÃDA")
        print("-"*60)
        print(f"ğŸ“· Arquivo: {result['arquivo']}")
        print(f"ğŸ¯ EspÃ©cie Identificada: {result['especie']}")
        print(f"ğŸ“Š ConfianÃ§a: {result['confianca']}")
        print(f"â­ Qualidade da PrediÃ§Ã£o: {result['qualidade_predicao']}")
        print(f"\n{result['recomendacao']}")
        
        if "info_detalhada" in result:
            info = result["info_detalhada"]
            print("\nğŸ“š INFORMAÃ‡Ã•ES DA ESPÃ‰CIE:")
            print(f"  Nome Comum: {info.get('nome_comum', 'N/A')}")
            print(f"  PerÃ­odo: {info.get('periodo', 'N/A')}")
            print(f"  Habitat: {info.get('habitat', 'N/A')}")
            print(f"  Tamanho: {info.get('tamanho', 'N/A')}")
            print(f"  DescriÃ§Ã£o: {info.get('descricao', 'N/A')}")
        
        print("\nğŸ† TOP 3 POSSIBILIDADES:")
        for i, pred in enumerate(result["top_3_predicoes"], 1):
            print(f"  {i}. {pred['especie']}: {pred['confianca']}")
    
    print("="*60)

def interactive_menu():
    """Menu interativo melhorado"""
    predictor = FossilPredictor()
    
    while True:
        print("\nğŸ§¬ === ANALISADOR DE DNA FÃ“SSIL v3.0 ===")
        print("1. ğŸ“ Analisar imagem (com TTA - mais preciso)")
        print("2. âš¡ AnÃ¡lise rÃ¡pida (sem TTA)")
        print("3. ğŸ“‚ Analisar pasta inteira")
        print("4. ğŸ” Ver imagens disponÃ­veis")
        print("5. âŒ Sair")
        
        opcao = input("\nEscolha (1-5): ").strip()
        
        if opcao == "1":
            caminho = input("ğŸ“ Caminho da imagem: ").strip().strip('"\'')
            if caminho and os.path.exists(caminho):
                result = predictor.predict_species(caminho, use_tta=True)
                display_result(result)
            else:
                print("âŒ Arquivo nÃ£o encontrado!")
        
        elif opcao == "2":
            caminho = input("ğŸ“ Caminho da imagem: ").strip().strip('"\'')
            if caminho and os.path.exists(caminho):
                result = predictor.predict_species(caminho, use_tta=False)
                display_result(result)
            else:
                print("âŒ Arquivo nÃ£o encontrado!")
        
        elif opcao == "3":
            pasta = input("ğŸ“‚ Caminho da pasta: ").strip().strip('"\'')
            if pasta and os.path.exists(pasta):
                results = predictor.analyze_batch(pasta)
                for result in results:
                    display_result(result)
                print(f"\nâœ… Total de {len(results)} imagens analisadas")
            else:
                print("âŒ Pasta nÃ£o encontrada!")
        
        elif opcao == "4":
            # Listar imagens em pastas comuns
            pastas = ["data/test", "test", "images", "."]
            encontradas = []
            
            for pasta in pastas:
                if os.path.exists(pasta):
                    for file in os.listdir(pasta):
                        if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                            encontradas.append(os.path.join(pasta, file))
            
            if encontradas:
                print(f"\nğŸ“‹ {len(encontradas)} imagens encontradas:")
                for i, img in enumerate(encontradas, 1):
                    print(f"  {i}. {img}")
                
                escolha = input(f"\nAnalisar qual? (1-{len(encontradas)}) ou 0 para voltar: ")
                try:
                    idx = int(escolha) - 1
                    if 0 <= idx < len(encontradas):
                        result = predictor.predict_species(encontradas[idx])
                        display_result(result)
                except:
                    pass
            else:
                print("âŒ Nenhuma imagem encontrada!")
        
        elif opcao == "5":
            print("ğŸ‘‹ AtÃ© logo!")
            break
        
        else:
            print("âŒ OpÃ§Ã£o invÃ¡lida!")

# ExecuÃ§Ã£o principal
if __name__ == "__main__":
    # Verificar se modelo existe
    if not os.path.exists(MODEL_PATH):
        print("âš ï¸ ATENÃ‡ÃƒO: Modelo nÃ£o encontrado!")
        print("Execute primeiro o script de treinamento (train.py)")
    else:
        interactive_menu()